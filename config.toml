# backend     = "ollama"
ollama_host = "192.168.1.68"

backend = "anthropic"  

# whisper_model = "small"
# device        = "cpu"

whisper_model = "medium"
device      = "cuda"